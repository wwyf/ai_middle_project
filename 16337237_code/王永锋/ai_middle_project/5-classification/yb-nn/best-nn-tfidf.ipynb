{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] <ipython-input-1-8dd56ce29e25> <ipython-input-1-8dd56ce29e25> - <module> line 23 - \n",
      "hello world\n",
      " - (2018-10-21 02:35:18)\n",
      "\n",
      "[DEBUG] __init__ __init__.py - pylab_setup line 90 - \n",
      "backend module://ipykernel.pylab.backend_inline version unknown\n",
      " - (2018-10-21 02:35:18)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# sys.path.append(r'E:/0code')\n",
    "sys.path.append(r'/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/mylearn')\n",
    "sys.path.append(r'/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code')\n",
    "# sys.path.append('/Users/yanbin/Documents/Projects/AI-Middle-Project/')\n",
    "# sys.path.append('/Users/yanbin/Documents/Projects/mylearn')\n",
    "\n",
    "# sys.path.append('/home/wyf/0code/AI-Middle-Project/')\n",
    "# sys.path.append('/home/wyf/0code/mylearn')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from logger import get_logger\n",
    "from neural_network import MLPClassifier\n",
    "from pyml.model_selection import KFold\n",
    "from pyml.model_selection import ShuffleSplit\n",
    "from pyml.metrics.classification import precision_score\n",
    "\n",
    "\n",
    "mylogger = get_logger(__name__)\n",
    "mylogger.debug('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_vec2doc_2 = np.load('../data/wyf-train_X-doc2vec-500.npy')\n",
    "test_X_vec2doc_2 = np.load('../data/wyf-test_X-doc2vec-500.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_vec2doc = np.load('../data/clean/trainX_vec2doc-24000-500.npy')\n",
    "test_X_vec2doc = np.load('../data/clean/testX_vec2doc-6000-500.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tfidf = np.load('../data/clean/trainX_tfidf-24000-62761.npy')\n",
    "test_X_tfidf = np.load('../data/clean/testX_tfidf-6000-62761.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_onehot = np.load('../data/clean/trainX_onehot-24000-62761.npy')\n",
    "test_X_onehot = np.load('../data/clean/testX_onthot-6000-62761.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ori_Y = np.load('../data/clean/trainY_24000.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用tfidf进行交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62761, 24000), (24000, 1), (62761, 6000))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X_tfidf.T\n",
    "test_X = test_X_tfidf.T\n",
    "train_Y  = train_ori_Y.reshape((-1,1))\n",
    "train_X.shape,train_Y.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((62761, 24000), (24000, 1), (62761, 6000))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = pd.DataFrame(train_X)\n",
    "test_X = pd.DataFrame(test_X)\n",
    "train_Y = pd.DataFrame(train_Y)\n",
    "train_X.shape,train_Y.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[0] loss 0.6932099822182799\n",
      " - (2018-10-21 02:38:58)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5004166666666666, training score 0.5036458333333333\n",
      " - (2018-10-21 02:39:04)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[10] loss 0.692506830664927\n",
      " - (2018-10-21 02:39:32)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.49833333333333335, training score 0.5197916666666667\n",
      " - (2018-10-21 02:39:37)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[20] loss 0.6928512054722534\n",
      " - (2018-10-21 02:40:04)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.50125, training score 0.5145833333333333\n",
      " - (2018-10-21 02:40:09)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[30] loss 0.6930667428312857\n",
      " - (2018-10-21 02:40:36)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5158333333333334, training score 0.5041666666666667\n",
      " - (2018-10-21 02:40:41)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[40] loss 0.6935815830972094\n",
      " - (2018-10-21 02:41:08)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.49895833333333334, training score 0.5229166666666667\n",
      " - (2018-10-21 02:41:13)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[50] loss 0.6927633489302178\n",
      " - (2018-10-21 02:41:40)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5160416666666666, training score 0.5270833333333333\n",
      " - (2018-10-21 02:41:45)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[60] loss 0.6930390220893407\n",
      " - (2018-10-21 02:42:12)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.524375, training score 0.5177083333333333\n",
      " - (2018-10-21 02:42:17)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[70] loss 0.6924609161620328\n",
      " - (2018-10-21 02:42:45)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.516875, training score 0.5302083333333333\n",
      " - (2018-10-21 02:42:49)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[80] loss 0.6925111263696917\n",
      " - (2018-10-21 02:43:17)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.521875, training score 0.5213541666666667\n",
      " - (2018-10-21 02:43:21)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[90] loss 0.6918316924335814\n",
      " - (2018-10-21 02:43:49)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5427083333333333, training score 0.5609375\n",
      " - (2018-10-21 02:43:54)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[100] loss 0.6920409920350715\n",
      " - (2018-10-21 02:44:21)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.516875, training score 0.5317708333333333\n",
      " - (2018-10-21 02:44:26)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[110] loss 0.6921174300654118\n",
      " - (2018-10-21 02:44:53)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5425, training score 0.5427083333333333\n",
      " - (2018-10-21 02:44:58)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[120] loss 0.6916037862552147\n",
      " - (2018-10-21 02:45:25)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.519375, training score 0.5208333333333334\n",
      " - (2018-10-21 02:45:30)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[130] loss 0.6920976223398321\n",
      " - (2018-10-21 02:45:57)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5264583333333334, training score 0.5302083333333333\n",
      " - (2018-10-21 02:46:02)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[140] loss 0.6921407521679627\n",
      " - (2018-10-21 02:46:29)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.543125, training score 0.5296875\n",
      " - (2018-10-21 02:46:34)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[150] loss 0.6916372652768906\n",
      " - (2018-10-21 02:47:01)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5172916666666667, training score 0.5380208333333333\n",
      " - (2018-10-21 02:47:06)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[160] loss 0.6906236142086973\n",
      " - (2018-10-21 02:47:33)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5008333333333334, training score 0.5395833333333333\n",
      " - (2018-10-21 02:47:38)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[170] loss 0.6915730757882488\n",
      " - (2018-10-21 02:48:05)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5239583333333333, training score 0.528125\n",
      " - (2018-10-21 02:48:10)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[180] loss 0.6917776127313143\n",
      " - (2018-10-21 02:48:37)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5477083333333334, training score 0.5458333333333333\n",
      " - (2018-10-21 02:48:42)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[190] loss 0.6907064710992111\n",
      " - (2018-10-21 02:49:09)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5110416666666666, training score 0.5244791666666667\n",
      " - (2018-10-21 02:49:14)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[200] loss 0.6921091056110178\n",
      " - (2018-10-21 02:49:41)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5485416666666667, training score 0.534375\n",
      " - (2018-10-21 02:49:46)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[210] loss 0.6905442222771024\n",
      " - (2018-10-21 02:50:13)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5141666666666667, training score 0.5244791666666667\n",
      " - (2018-10-21 02:50:18)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[220] loss 0.6913805198277717\n",
      " - (2018-10-21 02:50:45)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.5283333333333333, training score 0.5145833333333333\n",
      " - (2018-10-21 02:50:50)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 207 - \n",
      "[230] loss 0.6910111176839616\n",
      " - (2018-10-21 02:51:17)\n",
      "\n",
      "[INFO] multilayer_perceptron multilayer_perceptron.py - __train line 225 - \n",
      "validation score 0.515625, training score 0.5265625\n",
      " - (2018-10-21 02:51:22)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1,0.5]\n",
    "# learning_rates = [0.5, 0.3, 0.1, 0.05, 0.02, 0.01]\n",
    "\n",
    "n_splits = 1\n",
    "ms = ShuffleSplit(n_splits=n_splits,test_size=0.2)\n",
    "models = []\n",
    "for train_indices, valid_indices in ms.split(train_X_tfidf):\n",
    "    for learning_rate in learning_rates:\n",
    "        train_train_X = train_X.iloc[:,train_indices]\n",
    "        train_train_Y = train_Y.iloc[train_indices,:]\n",
    "        train_valid_X = train_X.iloc[:,valid_indices]\n",
    "        train_valid_Y = train_Y.iloc[valid_indices,:]\n",
    "        mlpc = MLPClassifier(verbose=False, \n",
    "            # 忽略输入和输出层。中间层的结点数。例如 本例子为 input -> 8 -> 4 -> 2（2分类）\n",
    "            hidden_layer_sizes=(4,), \n",
    "            activation='relu', # 'relu', 'sigmoid'. 更多函数，等待支持\n",
    "            max_iter=5000, # 迭代次数\n",
    "            learning_rate_init=learning_rate, \n",
    "            warm_start=True,  # True就好了\n",
    "            mini_batch='auto', # 保持auto\n",
    "            step_size=10, # 多少个iteration后，才进行“输出loss”，输出“准确度”，保存模型文件，这三个操作?\n",
    "            load_from_file=False, # 读文件恢复模型吗\n",
    "            dump_file=False, # 要不要把模型写入文件？\n",
    "            validation_set=(train_valid_X, train_valid_Y) # 要不要给一个validation set？（仅用来输出这个集合的准确度)\n",
    "        )\n",
    "        mlpc.fit(train_train_X, train_train_Y)\n",
    "        r = mlpc.score(train_valid_X, train_valid_Y)\n",
    "        models.append(mlpc)\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,model in enumerate(models):\n",
    "    m = model.information\n",
    "    num_iterations = list(m.keys())\n",
    "    costs = [m[i][0]  for i in num_iterations]\n",
    "    valid_scores = [m[i][1]  for i in num_iterations]\n",
    "    train_scores = [m[i][2]  for i in num_iterations]\n",
    "    plt.plot(num_iterations, valid_scores, '-', label='valid '+ str(learning_rates[i]))\n",
    "#     plt.plot(num_iterations, train_scores, ':', label='train '+ str(learning_rates[i]))\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
