{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(r'E:/0code')\n",
    "# sys.path.append(r'/home/wyf/0code')\n",
    "# sys.path.append(r'/home/wangyf226/0code')\n",
    "sys.path.append(r'/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import gensim\n",
    "import re\n",
    "import smart_open\n",
    "from pyml.feature_extraction.text import CountVectorizer\n",
    "from pyml.linear_model.classification import LogisticClassifier\n",
    "from pyml.neighbors.classification import KNeighborsClassifier\n",
    "from pyml.neural_network.classification import MLPClassifier\n",
    "from pyml.metrics.classification import precision_score\n",
    "from pyml.model_selection import KFold\n",
    "from pyml.model_selection import ShuffleSplit\n",
    "from pyml.preprocessing import StandardScaler\n",
    "from pyml.logger import logger\n",
    "import logging\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_vec2doc_2 = np.load('../data/wyf-train_X-doc2vec-500.npy')\n",
    "test_X_vec2doc_2 = np.load('../data/wyf-test_X-doc2vec-500.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_vec2doc = np.load('../data/clean/trainX_vec2doc-24000-500.npy')\n",
    "test_X_vec2doc = np.load('../data/clean/testX_vec2doc-6000-500.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_tfidf = np.load('../data/clean/trainX_tfidf-24000-62761.npy')\n",
    "test_X_tfidf = np.load('../data/clean/testX_tfidf-6000-62761.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_onehot = np.load('../data/clean/trainX_onehot-24000-62761.npy')\n",
    "test_X_onehot = np.load('../data/clean/testX_onthot-6000-62761.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X_vec2doc_2\n",
    "test_X = test_X_vec2doc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X_vec2doc\n",
    "test_X = test_X_vec2doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X_tfidf\n",
    "test_X = test_X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X_onehot\n",
    "test_X = test_X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = np.load('../data/clean/trainY_24000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 500), (24000,), (6000, 500))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape,train_Y.shape,test_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用没处理的句子生成的doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X_vec2doc_2\n",
    "test_X = test_X_vec2doc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.setLevel(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 遍历学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 0/5000  current cost: 4.367453083155591, train: 0.5544270833333333 ,test: 0.550625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 50/5000  current cost: 3.801178510653947, train: 0.5758333333333333 ,test: 0.566875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 100/5000  current cost: 3.344725174159691, train: 0.59234375 ,test: 0.5814583333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 150/5000  current cost: 2.9543176504178157, train: 0.6064583333333333 ,test: 0.5939583333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 200/5000  current cost: 2.629956153200473, train: 0.6194270833333333 ,test: 0.6083333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 250/5000  current cost: 2.363007192497398, train: 0.63109375 ,test: 0.618125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 300/5000  current cost: 2.1392509747849737, train: 0.640625 ,test: 0.6283333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 350/5000  current cost: 1.945355186239679, train: 0.64828125 ,test: 0.6379166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 400/5000  current cost: 1.7748044299941108, train: 0.6552083333333333 ,test: 0.6433333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 450/5000  current cost: 1.6229246279599387, train: 0.6615625 ,test: 0.6497916666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 500/5000  current cost: 1.485803548229162, train: 0.6669270833333333 ,test: 0.6560416666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 550/5000  current cost: 1.3612682613205334, train: 0.6733854166666666 ,test: 0.6610416666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 600/5000  current cost: 1.2482757288171011, train: 0.6788541666666666 ,test: 0.6675\n",
      "\n",
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 650/5000  current cost: nan, train: 0.6830729166666667 ,test: 0.6720833333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 700/5000  current cost: nan, train: 0.6875 ,test: 0.675\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 750/5000  current cost: nan, train: 0.6919270833333333 ,test: 0.6789583333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 800/5000  current cost: nan, train: 0.6953125 ,test: 0.6829166666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 850/5000  current cost: nan, train: 0.69796875 ,test: 0.685\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 900/5000  current cost: nan, train: 0.7003125 ,test: 0.6864583333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 950/5000  current cost: nan, train: 0.70203125 ,test: 0.689375\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1000/5000  current cost: nan, train: 0.7041145833333333 ,test: 0.6933333333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1050/5000  current cost: nan, train: 0.70609375 ,test: 0.6964583333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1100/5000  current cost: nan, train: 0.7069791666666667 ,test: 0.6997916666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1150/5000  current cost: nan, train: 0.7096875 ,test: 0.7022916666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1200/5000  current cost: nan, train: 0.71125 ,test: 0.703125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1250/5000  current cost: nan, train: 0.7130729166666666 ,test: 0.704375\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1300/5000  current cost: nan, train: 0.714375 ,test: 0.705625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1350/5000  current cost: nan, train: 0.7166145833333334 ,test: 0.7083333333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1400/5000  current cost: nan, train: 0.718125 ,test: 0.7097916666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1450/5000  current cost: nan, train: 0.7189583333333334 ,test: 0.710625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1500/5000  current cost: nan, train: 0.7201041666666667 ,test: 0.7122916666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1550/5000  current cost: nan, train: 0.7208854166666666 ,test: 0.713125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1600/5000  current cost: nan, train: 0.7220833333333333 ,test: 0.7133333333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1650/5000  current cost: nan, train: 0.723125 ,test: 0.7154166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1700/5000  current cost: nan, train: 0.7238020833333333 ,test: 0.7160416666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1750/5000  current cost: nan, train: 0.7244270833333334 ,test: 0.715625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1800/5000  current cost: nan, train: 0.72484375 ,test: 0.716875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1850/5000  current cost: nan, train: 0.7253645833333333 ,test: 0.718125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1900/5000  current cost: nan, train: 0.72578125 ,test: 0.7189583333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1950/5000  current cost: nan, train: 0.72671875 ,test: 0.72\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 2000/5000  current cost: 0.20293692018333856, train: 0.72734375 ,test: 0.7204166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 2050/5000  current cost: 0.1934769887343486, train: 0.7283333333333334 ,test: 0.7202083333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 2100/5000  current cost: 0.18466151905735345, train: 0.72859375 ,test: 0.720625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 2150/5000  current cost: 0.17643017996201835, train: 0.7291666666666666 ,test: 0.72125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 2200/5000  current cost: 0.16872963251778755, train: 0.7294270833333333 ,test: 0.7208333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 2250/5000  current cost: 0.16151338027148246, train: 0.7302604166666666 ,test: 0.72125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 2300/5000  current cost: 0.1547409096467811, train: 0.7308854166666666 ,test: 0.7208333333333333\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-05c0b3d6f328>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_and_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc19/wyf/0code/pyml/linear_model/classification.py\u001b[0m in \u001b[0;36mfit_and_valid\u001b[0;34m(self, X, Y, X_valid, Y_valid, watch)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0mthis_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minformation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc19/wyf/0code/pyml/linear_model/classification.py\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, X_valid, Y_valid)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m    185\u001b[0m         \u001b[0mY_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_pred : shape{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y_valid : shape{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc19/wyf/0code/pyml/linear_model/classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X_pred)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mY_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate_range = [0.03,0.05, 0.1, 0.15, 0.2]\n",
    "num_iteration = 5000\n",
    "mini_batch = 2000\n",
    "n_splits = 1\n",
    "ms = ShuffleSplit(n_splits=n_splits,test_size=0.2)\n",
    "models = []\n",
    "for i,learning_rate in enumerate(learning_rate_range):\n",
    "    for train_indices, test_indices in ms.split(train_X):\n",
    "        clf = LogisticClassifier(learning_rate=learning_rate, num_iterations=num_iteration, mini_batch=mini_batch)\n",
    "        clf.fit_and_valid(train_X[train_indices], train_Y[train_indices], train_X[test_indices], train_Y[test_indices])\n",
    "        y_pred = clf.predict(train_X[test_indices])\n",
    "        score = precision_score(train_Y[test_indices], y_pred)\n",
    "        print('i : {} score: {}'.format(i, score))\n",
    "        models.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7)) \n",
    "for i,m in enumerate(models):\n",
    "    plt.plot(range(0,len(m.information['valid_loss'])),m.information['valid_loss'],'-',label='valid '+str(hidden_sizes[i]) )\n",
    "#     plt.plot(range(0,len(m.information['train_loss'])),m.information['train_loss'],':',label='train '+str(hidden_sizes[i]) )\n",
    "    plt.yticks(np.arange(0.5, 0.95, 0.05))\n",
    "    ax = plt.gca()\n",
    "    ax.grid(True)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用onehot矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X_onehot\n",
    "test_X = test_X_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = train_X.astype('int64')\n",
    "# test_X = test_X.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA()\n",
    "# pca.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = pca.transform(train_X)\n",
    "# test_X = pca.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: invalid value encountered in log\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 0/500  current cost: nan, train: 0.49614583333333334 ,test: 0.4920833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 50/500  current cost: nan, train: 0.5267708333333333 ,test: 0.5225\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 100/500  current cost: nan, train: 0.5546354166666667 ,test: 0.5516666666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 150/500  current cost: nan, train: 0.5788020833333334 ,test: 0.575\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 200/500  current cost: nan, train: 0.60046875 ,test: 0.5977083333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 250/500  current cost: nan, train: 0.6203125 ,test: 0.6129166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 300/500  current cost: nan, train: 0.6386979166666666 ,test: 0.6270833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 350/500  current cost: nan, train: 0.6530729166666667 ,test: 0.6395833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 400/500  current cost: nan, train: 0.6667708333333333 ,test: 0.655625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 450/500  current cost: nan, train: 0.6757291666666667 ,test: 0.6639583333333333\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 0 score: 0.6754166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 0/500  current cost: nan, train: 0.47052083333333333 ,test: 0.47458333333333336\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 50/500  current cost: nan, train: 0.51859375 ,test: 0.5260416666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 100/500  current cost: nan, train: 0.5553125 ,test: 0.558125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 150/500  current cost: nan, train: 0.5861458333333334 ,test: 0.5860416666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 200/500  current cost: nan, train: 0.61328125 ,test: 0.6108333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 250/500  current cost: nan, train: 0.63375 ,test: 0.630625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 300/500  current cost: nan, train: 0.6533854166666667 ,test: 0.6472916666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 350/500  current cost: nan, train: 0.6669270833333333 ,test: 0.660625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 400/500  current cost: nan, train: 0.6794270833333333 ,test: 0.6704166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 450/500  current cost: nan, train: 0.690625 ,test: 0.6820833333333334\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 1 score: 0.6902083333333333\n"
     ]
    }
   ],
   "source": [
    "learning_rate_range = [0.15, 0.2]\n",
    "num_iteration = 500\n",
    "mini_batch = 0\n",
    "n_splits = 1\n",
    "ms = ShuffleSplit(n_splits=n_splits,test_size=0.2)\n",
    "models_2 = []\n",
    "for i,learning_rate in enumerate(learning_rate_range):\n",
    "    for train_indices, test_indices in ms.split(train_X):\n",
    "        clf = LogisticClassifier(learning_rate=learning_rate, num_iterations=num_iteration, mini_batch=mini_batch)\n",
    "        clf.fit_and_valid(train_X[train_indices], train_Y[train_indices], train_X[test_indices], train_Y[test_indices])\n",
    "        y_pred = clf.predict(train_X[test_indices])\n",
    "        score = precision_score(train_Y[test_indices], y_pred)\n",
    "        print('i : {} score: {}'.format(i, score))\n",
    "        models_2.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i,m in enumerate(models_2):\n",
    "    plt.plot(range(0,len(m.information['test_loss'])),m.information['test_loss'],'-',label='valid '+str(learning_rate_range[i]) )\n",
    "#     plt.plot(range(0,len(m.information['train_loss'])),m.information['train_loss'],':',label='train '+str(learning_rate_range[i]) )\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: divide by zero encountered in log\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: invalid value encountered in log\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "/BIGDATA1/nsccgz_yfdu_1/asc19/wyf/0code/pyml/linear_model/classification.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "  cost = -1 / m * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A))\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 0/2000  current cost: nan, train: 0.47791666666666666 ,test: 0.46875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 50/2000  current cost: nan, train: 0.5086458333333334 ,test: 0.49541666666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 100/2000  current cost: nan, train: 0.53984375 ,test: 0.5283333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 150/2000  current cost: nan, train: 0.5635416666666667 ,test: 0.556875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 200/2000  current cost: nan, train: 0.5891666666666666 ,test: 0.583125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 250/2000  current cost: nan, train: 0.6088020833333333 ,test: 0.6054166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 300/2000  current cost: nan, train: 0.6265625 ,test: 0.6254166666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 350/2000  current cost: nan, train: 0.6438020833333333 ,test: 0.6402083333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 400/2000  current cost: nan, train: 0.6555208333333333 ,test: 0.651875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 450/2000  current cost: nan, train: 0.6672916666666666 ,test: 0.6647916666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 500/2000  current cost: nan, train: 0.67765625 ,test: 0.6758333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 550/2000  current cost: nan, train: 0.6868229166666666 ,test: 0.6827083333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 600/2000  current cost: nan, train: 0.6943229166666667 ,test: 0.6891666666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 650/2000  current cost: nan, train: 0.7018229166666666 ,test: 0.6945833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 700/2000  current cost: nan, train: 0.7075 ,test: 0.6985416666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 750/2000  current cost: nan, train: 0.7132291666666667 ,test: 0.704375\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 800/2000  current cost: nan, train: 0.7193229166666667 ,test: 0.7102083333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 850/2000  current cost: nan, train: 0.7256770833333334 ,test: 0.7166666666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 900/2000  current cost: nan, train: 0.73078125 ,test: 0.7208333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 950/2000  current cost: nan, train: 0.7355208333333333 ,test: 0.7252083333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1000/2000  current cost: nan, train: 0.7397916666666666 ,test: 0.7285416666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1050/2000  current cost: nan, train: 0.74375 ,test: 0.7325\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1100/2000  current cost: nan, train: 0.7470833333333333 ,test: 0.7358333333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1150/2000  current cost: nan, train: 0.75046875 ,test: 0.73875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1200/2000  current cost: nan, train: 0.7530208333333334 ,test: 0.74125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1250/2000  current cost: nan, train: 0.75671875 ,test: 0.745\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1300/2000  current cost: nan, train: 0.7594270833333333 ,test: 0.7489583333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1350/2000  current cost: nan, train: 0.7616666666666667 ,test: 0.7497916666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1400/2000  current cost: nan, train: 0.7640625 ,test: 0.75125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1450/2000  current cost: nan, train: 0.76609375 ,test: 0.7547916666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1500/2000  current cost: nan, train: 0.7689583333333333 ,test: 0.756875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1550/2000  current cost: nan, train: 0.77140625 ,test: 0.7595833333333334\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1600/2000  current cost: nan, train: 0.7742708333333334 ,test: 0.7620833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1650/2000  current cost: nan, train: 0.7763020833333333 ,test: 0.764375\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1700/2000  current cost: nan, train: 0.7788541666666666 ,test: 0.766875\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1750/2000  current cost: nan, train: 0.78046875 ,test: 0.7691666666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1800/2000  current cost: nan, train: 0.7822916666666667 ,test: 0.77125\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1850/2000  current cost: nan, train: 0.7838541666666666 ,test: 0.7727083333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1900/2000  current cost: nan, train: 0.785625 ,test: 0.7741666666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 1950/2000  current cost: nan, train: 0.7871875 ,test: 0.77625\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i : 0 score: 0.7770833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 0/2000  current cost: nan, train: 0.5497916666666667 ,test: 0.5575\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 50/2000  current cost: nan, train: 0.5846354166666666 ,test: 0.585625\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 100/2000  current cost: nan, train: 0.6118229166666667 ,test: 0.6129166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 150/2000  current cost: nan, train: 0.63421875 ,test: 0.6320833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 200/2000  current cost: nan, train: 0.6509895833333333 ,test: 0.6439583333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 250/2000  current cost: nan, train: 0.6665104166666667 ,test: 0.6545833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 300/2000  current cost: nan, train: 0.6797916666666667 ,test: 0.6685416666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 350/2000  current cost: nan, train: 0.6910416666666667 ,test: 0.6795833333333333\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 400/2000  current cost: nan, train: 0.701875 ,test: 0.6922916666666666\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 450/2000  current cost: nan, train: 0.7114583333333333 ,test: 0.699375\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 500/2000  current cost: nan, train: 0.7198958333333333 ,test: 0.7054166666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 550/2000  current cost: nan, train: 0.7261979166666667 ,test: 0.7097916666666667\n",
      "\n",
      "[    INFO] - [classification] - [176] - [fit_and_valid] \n",
      "train 600/2000  current cost: nan, train: 0.7335416666666666 ,test: 0.7158333333333333\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1e70376410ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrain_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_and_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_Y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc19/wyf/0code/pyml/linear_model/classification.py\u001b[0m in \u001b[0;36mfit_and_valid\u001b[0;34m(self, X, Y, X_valid, Y_valid, watch)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_batch : {}\\nshape:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Y_batch : {}\\nshape:{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc19/wyf/0code/pyml/linear_model/classification.py\u001b[0m in \u001b[0;36moptimize_single\u001b[0;34m(self, w, b, X, Y)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \"\"\"\n\u001b[1;32m    111\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0ml2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_l2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asc19/wyf/0code/pyml/linear_model/classification.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, w, b, X, Y)\u001b[0m\n\u001b[1;32m     61\u001b[0m         self.information = {\n\u001b[1;32m     62\u001b[0m             \u001b[0;34m'test_loss'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;34m'train_loss'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0;34m'cost'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         }\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate_range = [0.15, 0.2]\n",
    "num_iteration = 2000\n",
    "mini_batch = 0\n",
    "n_splits = 1\n",
    "ms = ShuffleSplit(n_splits=n_splits,test_size=0.2)\n",
    "models_3 = []\n",
    "for i,learning_rate in enumerate(learning_rate_range):\n",
    "    for train_indices, test_indices in ms.split(train_X):\n",
    "        clf = LogisticClassifier(learning_rate=learning_rate, num_iterations=num_iteration, mini_batch=mini_batch)\n",
    "        clf.fit_and_valid(train_X[train_indices], train_Y[train_indices], train_X[test_indices], train_Y[test_indices])\n",
    "        y_pred = clf.predict(train_X[test_indices])\n",
    "        score = precision_score(train_Y[test_indices], y_pred)\n",
    "        print('i : {} score: {}'.format(i, score))\n",
    "        models_3.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
